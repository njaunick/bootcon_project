{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9898457,"sourceType":"datasetVersion","datasetId":6080255},{"sourceId":9898868,"sourceType":"datasetVersion","datasetId":6080553},{"sourceId":9900142,"sourceType":"datasetVersion","datasetId":6081425}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAgWSlVtnGuL","outputId":"40f586b6-8b32-4867-efb5-bf2a53b9169f","execution":{"iopub.status.busy":"2024-11-22T01:02:14.536142Z","iopub.execute_input":"2024-11-22T01:02:14.537021Z","iopub.status.idle":"2024-11-22T01:02:23.468918Z","shell.execute_reply.started":"2024-11-22T01:02:14.536983Z","shell.execute_reply":"2024-11-22T01:02:23.467943Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nfrom datasets import load_dataset\nimport kagglehub\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score\nimport os","metadata":{"id":"vcqludIP3Y53","execution":{"iopub.status.busy":"2024-11-22T01:02:56.430836Z","iopub.execute_input":"2024-11-22T01:02:56.431578Z","iopub.status.idle":"2024-11-22T01:02:56.436017Z","shell.execute_reply.started":"2024-11-22T01:02:56.431512Z","shell.execute_reply":"2024-11-22T01:02:56.435041Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Importing Data","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"spikecodes/911-call-transcripts\")","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:02:59.717457Z","iopub.execute_input":"2024-11-22T01:02:59.717827Z","iopub.status.idle":"2024-11-22T01:03:00.534696Z","shell.execute_reply.started":"2024-11-22T01:02:59.717799Z","shell.execute_reply":"2024-11-22T01:03:00.534012Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:02.679851Z","iopub.execute_input":"2024-11-22T01:03:02.680192Z","iopub.status.idle":"2024-11-22T01:03:02.686483Z","shell.execute_reply.started":"2024-11-22T01:03:02.680162Z","shell.execute_reply":"2024-11-22T01:03:02.685485Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['messages'],\n        num_rows: 518\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Convert the 'train' split to a pandas DataFrame\ndf = ds['train'].to_pandas()\n\n# Display the DataFrame\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:05.370017Z","iopub.execute_input":"2024-11-22T01:03:05.370957Z","iopub.status.idle":"2024-11-22T01:03:05.459363Z","shell.execute_reply.started":"2024-11-22T01:03:05.370920Z","shell.execute_reply":"2024-11-22T01:03:05.458599Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                              messages\n0    [{'role': 'assistant', 'content': '9-1-1, what...\n1    [{'role': 'assistant', 'content': '9-1-1, what...\n2    [{'role': 'assistant', 'content': '9-1-1, what...\n3    [{'role': 'assistant', 'content': '9-1-1, what...\n4    [{'role': 'assistant', 'content': '9-1-1, what...\n..                                                 ...\n513  [{'role': 'assistant', 'content': '9-1-1, what...\n514  [{'role': 'assistant', 'content': '9-1-1, what...\n515  [{'role': 'assistant', 'content': '9-1-1, what...\n516  [{'role': 'assistant', 'content': '9-1-1, what...\n517  [{'role': 'assistant', 'content': '9-1-1, what...\n\n[518 rows x 1 columns]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df['text'] = df['messages'].apply(lambda x: ' '.join([m['content'] for m in x if m['content'] is not None]))","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:13.011862Z","iopub.execute_input":"2024-11-22T01:03:13.012601Z","iopub.status.idle":"2024-11-22T01:03:13.023347Z","shell.execute_reply.started":"2024-11-22T01:03:13.012561Z","shell.execute_reply":"2024-11-22T01:03:13.022500Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Create a list to store the expanded data\nexpanded_data = []\n\n# Iterate through each row in the original DataFrame\nfor index, row in df.iterrows():\n    for message in row['messages']:\n        expanded_data.append({\n            'original_index': index,\n            'role': message['role'],\n            'content': message['content']\n        })\n\n# Create the expanded DataFrame from the list of dictionaries\nexpanded_df = pd.DataFrame(expanded_data)\n\n# Display the first few rows of the new DataFrame\nprint(expanded_df.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:40.978263Z","iopub.execute_input":"2024-11-22T01:03:40.978634Z","iopub.status.idle":"2024-11-22T01:03:41.044133Z","shell.execute_reply.started":"2024-11-22T01:03:40.978604Z","shell.execute_reply":"2024-11-22T01:03:41.043305Z"},"trusted":true},"outputs":[{"name":"stdout","text":"   original_index       role  \\\n0               0  assistant   \n1               0       user   \n2               0  assistant   \n3               0       user   \n4               0  assistant   \n5               0       user   \n6               0  assistant   \n7               0       user   \n8               0  assistant   \n9               0       user   \n\n                                             content  \n0                      9-1-1, what's your emergency?  \n1  I'm at West High School. There's a guy with a ...  \n2                                 Which high school?  \n3                                         West High.  \n4  Okay, we have the police dispatched. Can you g...  \n5  I don't know. The guy is just running through ...  \n6   Can someone give me a description of the person?  \n7      I don't know. Can anybody give a description?  \n8  Do we know where in the building? Is he white,...  \n9                                      I don't know.  \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"expanded_df['label'] = expanded_df['role'].apply(lambda x: 1 if x == 'assistant' else 0)","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:46.200958Z","iopub.execute_input":"2024-11-22T01:03:46.201315Z","iopub.status.idle":"2024-11-22T01:03:46.214712Z","shell.execute_reply.started":"2024-11-22T01:03:46.201284Z","shell.execute_reply":"2024-11-22T01:03:46.213804Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"expanded_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:52.493002Z","iopub.execute_input":"2024-11-22T01:03:52.493759Z","iopub.status.idle":"2024-11-22T01:03:52.505492Z","shell.execute_reply.started":"2024-11-22T01:03:52.493724Z","shell.execute_reply":"2024-11-22T01:03:52.504723Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"expanded_df.set_index('original_index', inplace=True)\nexpanded_df","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:03:58.276973Z","iopub.execute_input":"2024-11-22T01:03:58.277300Z","iopub.status.idle":"2024-11-22T01:03:58.287953Z","shell.execute_reply.started":"2024-11-22T01:03:58.277274Z","shell.execute_reply":"2024-11-22T01:03:58.287192Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                     role                                            content  \\\noriginal_index                                                                 \n0               assistant                      9-1-1, what's your emergency?   \n0                    user  I'm at West High School. There's a guy with a ...   \n0               assistant                                 Which high school?   \n0                    user                                         West High.   \n0               assistant  Okay, we have the police dispatched. Can you g...   \n...                   ...                                                ...   \n517             assistant                       Are you on a cordless phone?   \n517                  user       I have a cordless phone, but I use a walker.   \n517             assistant  You can go ahead and hang up with me and go ah...   \n517                  user                                    All right. Bye.   \n517             assistant                                               Bye.   \n\n                label  \noriginal_index         \n0                   1  \n0                   0  \n0                   1  \n0                   0  \n0                   1  \n...               ...  \n517                 1  \n517                 0  \n517                 1  \n517                 0  \n517                 1  \n\n[25918 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>role</th>\n      <th>content</th>\n      <th>label</th>\n    </tr>\n    <tr>\n      <th>original_index</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>assistant</td>\n      <td>9-1-1, what's your emergency?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>user</td>\n      <td>I'm at West High School. There's a guy with a ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>assistant</td>\n      <td>Which high school?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>user</td>\n      <td>West High.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>assistant</td>\n      <td>Okay, we have the police dispatched. Can you g...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>517</th>\n      <td>assistant</td>\n      <td>Are you on a cordless phone?</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>517</th>\n      <td>user</td>\n      <td>I have a cordless phone, but I use a walker.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>517</th>\n      <td>assistant</td>\n      <td>You can go ahead and hang up with me and go ah...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>517</th>\n      <td>user</td>\n      <td>All right. Bye.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>517</th>\n      <td>assistant</td>\n      <td>Bye.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>25918 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"expanded_df['content'].dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:04:35.823143Z","iopub.execute_input":"2024-11-22T01:04:35.823552Z","iopub.status.idle":"2024-11-22T01:04:35.831148Z","shell.execute_reply.started":"2024-11-22T01:04:35.823497Z","shell.execute_reply":"2024-11-22T01:04:35.829967Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# First look at what we're removing\nprint(\"Entries being removed:\")\nprint(expanded_df[expanded_df.index.get_level_values('original_index').isin([78, 451])])\n\n# Then remove them\nexpanded_df = expanded_df[~expanded_df.index.get_level_values('original_index').isin([78, 451])]","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:04:39.648432Z","iopub.execute_input":"2024-11-22T01:04:39.648857Z","iopub.status.idle":"2024-11-22T01:04:39.661025Z","shell.execute_reply.started":"2024-11-22T01:04:39.648805Z","shell.execute_reply":"2024-11-22T01:04:39.660209Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Entries being removed:\n                     role                                            content  \\\noriginal_index                                                                 \n78              assistant                      9-1-1, what's your emergency?   \n78                   user                                  1620 Green Place.   \n78              assistant                                         1620 what?   \n78                   user                                       Green Place.   \n78              assistant                 Green Place. Green like the color?   \n...                   ...                                                ...   \n451                  user                                   It's the police.   \n451             assistant  Okay. Step outside and do what they say. Just ...   \n451                  user                                      They're here.   \n451             assistant  Okay. Just put the phone down and do what they...   \n451                  user                                              Okay.   \n\n                label  \noriginal_index         \n78                  1  \n78                  0  \n78                  1  \n78                  0  \n78                  1  \n...               ...  \n451                 0  \n451                 1  \n451                 0  \n451                 1  \n451                 0  \n\n[119 rows x 3 columns]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(expanded_df['content'].tolist(), expanded_df['label'].tolist(), test_size=0.2, random_state=42)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"uMyOSrpp1-2q","outputId":"3d9328b2-8a9c-4747-ed54-4c551c4e686b","execution":{"iopub.status.busy":"2024-11-22T01:05:03.112931Z","iopub.execute_input":"2024-11-22T01:05:03.113707Z","iopub.status.idle":"2024-11-22T01:05:03.128273Z","shell.execute_reply.started":"2024-11-22T01:05:03.113673Z","shell.execute_reply":"2024-11-22T01:05:03.127565Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Print some statistics\nprint(f\"Total samples: {len(expanded_df)}\")\nprint(f\"Training samples: {len(train_texts)}\")\nprint(f\"Validation samples: {len(val_texts)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-22T01:05:06.717880Z","iopub.execute_input":"2024-11-22T01:05:06.718522Z","iopub.status.idle":"2024-11-22T01:05:06.723060Z","shell.execute_reply.started":"2024-11-22T01:05:06.718489Z","shell.execute_reply":"2024-11-22T01:05:06.722118Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total samples: 25799\nTraining samples: 20639\nValidation samples: 5160\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"expanded_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EmergencyCallDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\n# Set up tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)","metadata":{"id":"cc7gdUoL3I-F","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = EmergencyCallDataset(train_texts, train_labels, tokenizer, max_length=512)\nval_dataset = EmergencyCallDataset(val_texts, val_labels, tokenizer, max_length=512)","metadata":{"id":"_h0Em6LZ3QV1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up optimizer and scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\ntotal_steps = len(train_loader) * 10  # 10 epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlAQ-ldJ7BCB","outputId":"43a61076-4204-4481-e154-809ce55fd5c0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Set up device (GPU if available, otherwise CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Training loop\nfor epoch in range(10):\n    # Training phase\n    model.train()\n    for batch in train_loader:\n        # Clear previous gradients\n        optimizer.zero_grad()\n        \n        # Move data to device\n        inputs = {\n            'input_ids': batch['input_ids'].to(device),\n            'attention_mask': batch['attention_mask'].to(device),\n            'labels': batch['labels'].to(device)\n        }\n        \n        # Forward pass and calculate loss\n        outputs = model(**inputs)\n        loss = outputs.loss\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss = 0\n    correct = 0\n    total = 0\n    \n    # No gradient calculation needed for validation\n    with torch.no_grad():\n        for batch in val_loader:\n            # Move data to device\n            inputs = {\n                'input_ids': batch['input_ids'].to(device),\n                'attention_mask': batch['attention_mask'].to(device),\n                'labels': batch['labels'].to(device)\n            }\n            \n            # Get model predictions\n            outputs = model(**inputs)\n            \n            # Calculate validation loss\n            val_loss += outputs.loss.item()\n            \n            # Calculate accuracy\n            _, predictions = torch.max(outputs.logits, 1)\n            total += inputs['labels'].size(0)\n            correct += (predictions == inputs['labels']).sum().item()\n    \n    # Print epoch results\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy = (correct / total) * 100\n    print(f'Epoch {epoch+1}:')\n    print(f'  Validation Loss: {avg_val_loss:.4f}')\n    print(f'  Accuracy: {accuracy:.2f}%')\n    print('-' * 50)","metadata":{"id":"HdIcugwj7DwH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained('fine_tuned_bert_emergency_calls')\ntokenizer.save_pretrained('fine_tuned_bert_emergency_calls')","metadata":{"id":"Y5KhjzRm7ISA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"# Tokenize the data\ntokenized_train = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\ntokenized_test = tokenizer(val_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n\n\n# Hyperparameter grid\nlearning_rates = [1e-5, 5e-5, 1e-4]\ndropout_rates = [0.1, 0.3, 0.5]\nbatch_sizes = [16, 32]\n\nbest_accuracy = 0\nbest_params = {}\nbest_model = None\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Iterate over hyperparameters\nfor lr in learning_rates:\n    for dropout in dropout_rates:\n        for batch_size in batch_sizes:\n            print(f\"Training with lr={lr}, dropout={dropout}, batch_size={batch_size}\")\n\n            # Create model with specific dropout\n            model = BertForSequenceClassification.from_pretrained(\n                \"bert-base-uncased\", \n                num_labels=2,\n                hidden_dropout_prob=dropout\n            )\n            model.to(device)\n\n            # DataLoader with specific batch size\n            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n            # Define optimizer and criterion\n            optimizer = optim.AdamW(model.parameters(), lr=lr)\n            criterion = nn.CrossEntropyLoss()\n\n            # Train and evaluate\n            for epoch in range(3):  # Fixed number of epochs for tuning\n                model.train()\n                total_loss = 0\n                \n                for batch in train_loader:\n                    optimizer.zero_grad()\n                    inputs = {key: val.to(device) for key, val in batch.items()}\n                    outputs = model(**inputs)\n                    loss = criterion(outputs.logits, inputs['labels'])\n                    loss.backward()\n                    optimizer.step()\n                    total_loss += loss.item()\n\n                # Evaluate on validation set\n                model.eval()\n                all_preds = []\n                all_labels = []\n                \n                with torch.no_grad():\n                    for batch in val_loader:\n                        inputs = {key: val.to(device) for key, val in batch.items()}\n                        outputs = model(**inputs)\n                        preds = torch.argmax(outputs.logits, dim=1)\n                        all_preds.extend(preds.cpu().numpy())\n                        all_labels.extend(inputs['labels'].cpu().numpy())\n\n                val_accuracy = accuracy_score(all_labels, all_preds)\n                print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}, Val Accuracy: {val_accuracy}\")\n            if val_accuracy > best_accuracy:\n                best_accuracy = val_accuracy\n                best_params = {\n                    \"learning_rate\": lr,\n                    \"dropout\": dropout,\n                    \"batch_size\": batch_size,\n                }\n                best_model = model.state_dict()  # Save the model state\n\nprint(f\"Best Accuracy: {best_accuracy}\")\nprint(f\"Best Parameters: {best_params}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save the model with the best hyperparameters","metadata":{}},{"cell_type":"code","source":"# Save the best model\nif best_model is not None:\n    save_path = 'best_model.pth'\n    torch.save(best_model, save_path)\n    print(f\"Best model saved to {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}